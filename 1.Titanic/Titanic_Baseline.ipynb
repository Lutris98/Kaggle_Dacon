{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic_trial1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOYtZjvNF4i8xnoQP0TLpL+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lutris98/21_1Q/blob/master/1.Titanic/Titanic_trial1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaDmu6d-9pwA"
      },
      "source": [
        "# 1.EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNOjOEZEge3O"
      },
      "source": [
        "import pandas as pd \r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV #model_selection doesn't need mentioning, only the method does\r\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\r\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\r\n",
        "from lightgbm import LGBMClassifier\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import accuracy_score #given metric was accuracy\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5WPdAAm0Qsy",
        "outputId": "457901c0-2557-4cb4-e19c-3a2e44ea717b"
      },
      "source": [
        "from google.colab import drive #Korean Army banned me from using os resources so I learned new ways\r\n",
        "drive.mount('/content/gdrive')\r\n",
        "titanic_df=pd.read_csv('/content/gdrive/MyDrive/Dataset/titanic_train.csv') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "XNwPVclMMOJT",
        "outputId": "4c1cc197-931b-4f9c-ece9-0f642dd1e950"
      },
      "source": [
        "titanic_df.head(3) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500   NaN         S\n",
              "1            2         1       1  ...  71.2833   C85         C\n",
              "2            3         1       3  ...   7.9250   NaN         S\n",
              "\n",
              "[3 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGCRXDRJ3kA9",
        "outputId": "9714e4d4-e772-46f1-ebd5-63fcd1291cb4"
      },
      "source": [
        "print(titanic_df.info()) #objects are strings"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwrGPAnD4zXu"
      },
      "source": [
        "titanic_feature=titanic_df.drop(['Survived'], axis=1) #parameter axis is mandatory\r\n",
        "titanic_label=titanic_df['Survived']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGUl6OZO90ya"
      },
      "source": [
        "#2.Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hZHp8aYBSdj",
        "outputId": "6cb58dda-813e-4cb8-f0b2-0cf9166d7567"
      },
      "source": [
        "titanic_feature=titanic_feature.drop(['Name', 'Ticket'], axis=1) #1 #PassengerId will be useless but it is how the result should find people #drop method doesn't allow inplacing(Should check results along the way)\r\n",
        "titanic_feature['Age'].fillna(titanic_feature['Age'].mean(), inplace=True) #could be affecting, so average would minimize the loss(for further development, something could be inferred from sibsp&parch)\r\n",
        "titanic_feature['Cabin'].fillna('N', inplace=True) #inplacing so that additional object would be unnecesory\r\n",
        "titanic_feature['Embarked'].fillna('N',inplace=True) #Wonder features like this would be better off set random...\r\n",
        "print(titanic_feature.isnull().sum().sum()) #checking"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObS8b057FfAm",
        "outputId": "64cf991d-98a6-4009-fc83-945e85678a81"
      },
      "source": [
        "print('Sex distribution:\\n',titanic_feature['Sex'].value_counts()) #focusing on columns\r\n",
        "print('Cabin distribution\\n',titanic_feature['Cabin'].value_counts())\r\n",
        "print('Embarked distribution:\\n',titanic_feature['Embarked'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sex distribution:\n",
            " male      577\n",
            "female    314\n",
            "Name: Sex, dtype: int64\n",
            "Cabin distribution\n",
            " N              687\n",
            "B96 B98          4\n",
            "G6               4\n",
            "C23 C25 C27      4\n",
            "C22 C26          3\n",
            "              ... \n",
            "C82              1\n",
            "B71              1\n",
            "D21              1\n",
            "B69              1\n",
            "D46              1\n",
            "Name: Cabin, Length: 148, dtype: int64\n",
            "Embarked distribution:\n",
            " S    644\n",
            "C    168\n",
            "Q     77\n",
            "N      2\n",
            "Name: Embarked, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trpeRTyOG1nB"
      },
      "source": [
        "titanic_feature['Cabin']=titanic_df['Cabin'].str[:1] #Cabin needs insight that only the first character contains information #pd.str is applicable to series\r\n",
        "features=['Cabin','Sex','Embarked']\r\n",
        "for feature in features:\r\n",
        "  titanic_feature[feature]=LabelEncoder().fit_transform(titanic_feature[feature].astype(str)) #changing dtype of series"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPEjfjGrKtOr"
      },
      "source": [
        "#3.Cross validation & Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWHUJvRiK1ji"
      },
      "source": [
        "rf_clf=RandomForestClassifier(random_state=0) #Cross validation need models \r\n",
        "lgbm_clf=LGBMClassifier(random_state=0)\r\n",
        "X_train, X_test, y_train, y_test=train_test_split(titanic_feature, titanic_label, test_size=0.1,random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkrHw-VNbTv8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3f04dae-b188-4db1-dec8-46ab3171304a"
      },
      "source": [
        "rf_params={'n_estimators':[300],\r\n",
        "           'max_depth':[6,8,10,12], #similar to decisiontree\r\n",
        "           'min_samples_leaf':[8,12,18],\r\n",
        "           'min_samples_split':[8,16,20]}\r\n",
        "rf_gridcv=GridSearchCV(rf_clf, param_grid=rf_params, cv=5, n_jobs=-1) #using all CPU cores\r\n",
        "rf_gridcv.fit(X_train, y_train)\r\n",
        "print('best parameters:\\n',rf_gridcv.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters:\n",
            " {'max_depth': 6, 'min_samples_leaf': 8, 'min_samples_split': 20, 'n_estimators': 300}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJtKJuQ-e0Ap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9a2affe-0e63-42f6-80be-ce78c0da62c7"
      },
      "source": [
        "lgbm_params={'n_estimators':[300],\r\n",
        "             'num_leaves':[32,64],\r\n",
        "             'min_child_samples':[60,100],\r\n",
        "             'subsample':[0.8,1],\r\n",
        "             'max_depth':[160]}\r\n",
        "lgbm_gridcv=GridSearchCV(lgbm_clf, param_grid=lgbm_params, cv=5, n_jobs=-1) \r\n",
        "lgbm_gridcv.fit(X_train, y_train)\r\n",
        "print('best parameters:\\n',lgbm_gridcv.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters:\n",
            " {'max_depth': 160, 'min_child_samples': 100, 'n_estimators': 300, 'num_leaves': 32, 'subsample': 0.8}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1unUXEw_NMcH"
      },
      "source": [
        "#4.modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cjxu0w-0NQI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb400c7c-5e43-440a-c3d4-8df09254d714"
      },
      "source": [
        "rf_clf=RandomForestClassifier(n_estimators=300, max_depth=6, min_samples_leaf=8, min_samples_split=20, random_state=0) #Cross validation need models \r\n",
        "lgbm_clf=LGBMClassifier(n_estimators=300, num_leaves=32, min_child_samples=100, subsample=0.8, max_depth=160, random_state=0)\r\n",
        "vo_clf=VotingClassifier(estimators=[('RandomForest',rf_clf),('LightGBM',lgbm_clf)], voting='soft')\r\n",
        "vo_clf.fit(X_train, y_train)\r\n",
        "pred1=rf_clf.fit(X_train, y_train).predict(X_test)\r\n",
        "pred2=lgbm_clf.fit(X_train, y_train).predict(X_test)\r\n",
        "pred3=vo_clf.predict(X_test)\r\n",
        "print('Accuracy1:{0:.4f} Accuracy2:{1:.4f}'.format(accuracy_score(y_test,pred1), accuracy_score(y_test,pred2)))\r\n",
        "print('Final accuracy:{0:.4f}'.format(accuracy_score(y_test,pred3))) #from python3.6 should use fstring formatting  #:separates index and the number"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy1:0.8222 Accuracy2:0.8556\n",
            "Final accuracy:0.8556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOXTJAG5nVdH"
      },
      "source": [
        "# *Uploading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvKx24sQnlXR",
        "outputId": "b2c970b8-05dd-4d29-84ae-871b28385751"
      },
      "source": [
        "from google.colab import drive \r\n",
        "drive.mount('/content/gdrive')\r\n",
        "test_df=pd.read_csv('/content/gdrive/MyDrive/Dataset/titanic_test.csv') \r\n",
        "test_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  418 non-null    int64  \n",
            " 1   Pclass       418 non-null    int64  \n",
            " 2   Name         418 non-null    object \n",
            " 3   Sex          418 non-null    object \n",
            " 4   Age          332 non-null    float64\n",
            " 5   SibSp        418 non-null    int64  \n",
            " 6   Parch        418 non-null    int64  \n",
            " 7   Ticket       418 non-null    object \n",
            " 8   Fare         417 non-null    float64\n",
            " 9   Cabin        91 non-null     object \n",
            " 10  Embarked     418 non-null    object \n",
            "dtypes: float64(2), int64(4), object(5)\n",
            "memory usage: 36.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs_hGd2xoL22"
      },
      "source": [
        "test_df=test_df.drop(['Name', 'Ticket'], axis=1) #uploading needs the same preprocessing I did on training set(but no need to split feature&label)\r\n",
        "test_df['Age'].fillna(test_df['Age'].mean(), inplace=True) \r\n",
        "test_df['Fare'].fillna(test_df['Fare'].mean(), inplace=True) \r\n",
        "test_df['Cabin'].fillna('N', inplace=True) \r\n",
        "test_df['Cabin']=test_df['Cabin'].str[:1] \r\n",
        "features=['Cabin','Sex','Embarked']\r\n",
        "for feature in features:\r\n",
        "  test_df[feature]=LabelEncoder().fit_transform(test_df[feature].astype(str)) \r\n",
        "realpred=vo_clf.predict(test_df) #output of classifier is ndarray object\r\n",
        "realpred=pd.DataFrame(realpred, columns=['Survived']) #never forget[]\r\n",
        "Submit=pd.DataFrame({'PassengerId':test_df['PassengerId'],'Survived':realpred['Survived']}) #Data set by giving each column name and data\r\n",
        "Submit.head(3)\r\n",
        "Submit.to_csv('/content/gdrive/MyDrive/Dataset/Lutris_titanic1.csv', index = False) #The client doesn't want indice on submission"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXVyEpanGSr5"
      },
      "source": [
        "#*Feedback<br>\r\n",
        "*   Tuning must have been insufficient(I was impatient)<br>\r\n",
        "*   Could not use Logistic regression(Lack of training) \r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb0Q-Ufg6WhQ"
      },
      "source": [
        "#*Afterwords\r\n",
        "My first ever AI only got 77% on test XD<br>\r\n",
        "No worries for a beginner :)<br>\r\n",
        "New life goal=getting above 90% on most data sets"
      ]
    }
  ]
}
